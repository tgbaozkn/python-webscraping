{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Retrieving weather data for usak\n",
      "\n",
      "\n",
      "Currently retrieving data for usak: from 2018-01-01 to 2018-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:01.448900\n",
      "Currently retrieving data for usak: from 2018-02-01 to 2018-02-28\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:02.881188\n",
      "Currently retrieving data for usak: from 2018-03-01 to 2018-03-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:04.038832\n",
      "Currently retrieving data for usak: from 2018-04-01 to 2018-04-30\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:06.721272\n",
      "Currently retrieving data for usak: from 2018-05-01 to 2018-05-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:08.328976\n",
      "Currently retrieving data for usak: from 2018-06-01 to 2018-06-30\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:10.448428\n",
      "Currently retrieving data for usak: from 2018-07-01 to 2018-07-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:12.577189\n",
      "Currently retrieving data for usak: from 2018-08-01 to 2018-08-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:14.897839\n",
      "Currently retrieving data for usak: from 2018-09-01 to 2018-09-30\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:16.960642\n",
      "Currently retrieving data for usak: from 2018-10-01 to 2018-10-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:18.325850\n",
      "Currently retrieving data for usak: from 2018-11-01 to 2018-11-30\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:19.978891\n",
      "Currently retrieving data for usak: from 2018-12-01 to 2018-12-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:22.877211\n",
      "Currently retrieving data for usak: from 2019-01-01 to 2019-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:24.335731\n",
      "Currently retrieving data for usak: from 2019-02-01 to 2019-02-28\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:26.305609\n",
      "Currently retrieving data for usak: from 2019-03-01 to 2019-03-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:29.167325\n",
      "Currently retrieving data for usak: from 2019-04-01 to 2019-04-30\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:31.241125\n",
      "Currently retrieving data for usak: from 2019-05-01 to 2019-05-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:33.017118\n",
      "Currently retrieving data for usak: from 2019-06-01 to 2019-06-30\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:34.985174\n",
      "Currently retrieving data for usak: from 2019-07-01 to 2019-07-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:37.822024\n",
      "Currently retrieving data for usak: from 2019-08-01 to 2019-08-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:40.686158\n",
      "Currently retrieving data for usak: from 2019-09-01 to 2019-09-30\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:43.778473\n",
      "Currently retrieving data for usak: from 2019-10-01 to 2019-10-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:46.003735\n",
      "Currently retrieving data for usak: from 2019-11-01 to 2019-11-30\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:49.018986\n",
      "Currently retrieving data for usak: from 2019-12-01 to 2019-12-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:52.015249\n",
      "Currently retrieving data for usak: from 2020-01-01 to 2020-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:54.424474\n",
      "Currently retrieving data for usak: from 2020-02-01 to 2020-02-29\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:56.128262\n",
      "Currently retrieving data for usak: from 2020-03-01 to 2020-03-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:58.976759\n",
      "Currently retrieving data for usak: from 2020-04-01 to 2020-04-30\n",
      "Time elapsed (hh:mm:ss.ms) 0:01:01.257382\n",
      "Currently retrieving data for usak: from 2020-05-01 to 2020-05-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:01:02.614990\n",
      "Currently retrieving data for usak: from 2020-06-01 to 2020-06-30\n",
      "Time elapsed (hh:mm:ss.ms) 0:01:03.825834\n",
      "Currently retrieving data for usak: from 2020-07-01 to 2020-07-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:01:06.234299\n",
      "Currently retrieving data for usak: from 2020-08-01 to 2020-08-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:01:07.377654\n",
      "Currently retrieving data for usak: from 2020-09-01 to 2020-09-30\n",
      "Time elapsed (hh:mm:ss.ms) 0:01:08.521589\n",
      "Currently retrieving data for usak: from 2020-10-01 to 2020-10-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:01:10.436160\n",
      "Currently retrieving data for usak: from 2020-11-01 to 2020-11-30\n",
      "Time elapsed (hh:mm:ss.ms) 0:01:12.212854\n",
      "Currently retrieving data for usak: from 2020-12-01 to 2020-12-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:01:13.840253\n",
      "Currently retrieving data for usak: from 2021-01-01 to 2021-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:01:16.392185\n",
      "Currently retrieving data for usak: from 2021-02-01 to 2021-02-28\n",
      "Time elapsed (hh:mm:ss.ms) 0:01:18.815408\n",
      "Currently retrieving data for usak: from 2021-03-01 to 2021-03-18\n",
      "Time elapsed (hh:mm:ss.ms) 0:01:20.079999\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import urllib.parse\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "##################################\n",
    "# function to unnest json for each month\n",
    "#her ay için jsonu çıkarma fonksiyonu\n",
    "def extract_monthly_data(data):\n",
    "    num_days = len(data)\n",
    "    # initialize df_month to store return data\n",
    "    # veriyi döndrürürken depolmak için df_month oluşumu\n",
    "    df_month = pd.DataFrame()\n",
    "    for i in range(num_days):\n",
    "        # extract this day\n",
    "        #bugünü ayıklamak\n",
    "        d = data[i]\n",
    "        # astronomy data is the same for the whole day\n",
    "        #aynı gün için astronomi bilgileri \n",
    "        astr_df = pd.DataFrame(d['astronomy'])\n",
    "        # hourly data; temperature for each hour of the day\n",
    "        #saatlik veri ; günün hersaatinin sıcaklığı\n",
    "        hourly_df = pd.DataFrame(d['hourly'])\n",
    "        # this wanted_key will be duplicated and use 'ffill' to fill up the NAs\n",
    "        #bu NA ları doldurmak için 'ffill' kullanacak ve çoğaltacak olan istenen_anahtar(kelime)\n",
    "        wanted_keys = ['date', 'maxtempC', 'mintempC', 'totalSnow_cm', 'sunHour']  # The keys you want\n",
    "        subset_d = dict((k, d[k]) for k in wanted_keys if k in d)\n",
    "        this_df = pd.DataFrame(subset_d, index=[0])\n",
    "        df = pd.concat([this_df.reset_index(drop=True), astr_df], axis=1)\n",
    "        # concat selected astonomy columns with hourly data\n",
    "        #saatlik verileri olan seçili astronomi sutunları\n",
    "        df = pd.concat([df, hourly_df], axis=1)\n",
    "        df = df.fillna(method='ffill')\n",
    "        # make date_time columm to proper format\n",
    "        #formatı sağlamak için date_time sutununu yapmak\n",
    "        # fill leading zero for hours to 4 digits (0000-2400 hr)\n",
    "        #4 haneli saatler için 0 ile doldurmak\n",
    "        df['time'] = df['time'].apply(lambda x: x.zfill(4))\n",
    "        # keep only first 2 digit (00-24 hr) \n",
    "        #sadece saatin ilk iki hanesini almak\n",
    "        df['time'] = df['time'].str[:2]\n",
    "        # convert to pandas datetime\n",
    "        #pandas datetime a çevrilmesi\n",
    "        df['date_time'] = pd.to_datetime(df['date'] + ' ' + df['time'])\n",
    "        # keep only interested columns\n",
    "        #sadece ilgilenilen sutunların tutulması \n",
    "        col_to_keep = ['date_time', 'maxtempC', 'mintempC', 'totalSnow_cm', 'sunHour',\n",
    "                        'sunrise', 'sunset','DewPointC', 'FeelsLikeC', 'WindChillC',\n",
    "                       'cloudcover', 'humidity', 'precipMM', 'tempC', 'visibility', 'windspeedKmph']\n",
    "        df = df[col_to_keep]\n",
    "        df = df.loc[:,~df.columns.duplicated()]\n",
    "        df_month = pd.concat([df_month, df])\n",
    "    return (df_month)\n",
    "\n",
    "\n",
    "##################################\n",
    "# function to retrive data by date range and location\n",
    "#yer ve tarih sırasıyla veriyi alan fonksiyon \n",
    "# default frequency = 1 hr\n",
    "#standart frekans =  1 saat \n",
    "# each month costs 1 request (free trial 500 requests/key, as of 30-May-2019)\n",
    "def retrieve_this_location(api_key, location, start_date, end_date, frequency, response_cache_path):\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    # create list of first day of month for range between start and end dates non-inclusive (open)\n",
    "    list_mon_begin = pd.date_range(start_date, end_date, freq='MS', closed='right')\n",
    "    # convert to Series and add start_date at beginning\n",
    "    list_mon_begin = pd.concat([pd.Series(pd.to_datetime(start_date)), pd.Series(list_mon_begin)], ignore_index=True)\n",
    "\n",
    "    # create list of month end dates for range between start and end dates non-inclusive (open)\n",
    "    list_mon_end = pd.date_range(start_date, end_date, freq='M', closed='left')\n",
    "    # convert to Series and add end_date at end\n",
    "    list_mon_end = pd.concat([pd.Series(list_mon_end), pd.Series(pd.to_datetime(end_date))], ignore_index=True)\n",
    "    # count number of months to be retrieved\n",
    "    total_months = len(list_mon_begin)\n",
    "\n",
    "    # initialize df_hist to store return data\n",
    "    df_hist = pd.DataFrame()\n",
    "    for m in range(total_months):\n",
    "        start_d = str(list_mon_begin[m])[:10]\n",
    "        end_d = str(list_mon_end[m])[:10]\n",
    "        file_path = f'{response_cache_path}/{location}_{start_d}_{end_d}'\n",
    "        if response_cache_path and os.path.exists(file_path):\n",
    "            print('Reading cached data for ' + location + ': from ' + start_d + ' to ' + end_d)\n",
    "            with open(f'{response_cache_path}/{location}_{start_d}_{end_d}', 'r') as f:\n",
    "                json_data = json.load(f)\n",
    "        else:\n",
    "            print('Currently retrieving data for ' + location + ': from ' + start_d + ' to ' + end_d)\n",
    "            url_page = 'http://api.worldweatheronline.com/premium/v1/past-weather.ashx?key=' + api_key + '&q=' + location + '&format=json&date=' + start_d + '&enddate=' + end_d + '&tp=' + str(\n",
    "                frequency)\n",
    "            json_page = urllib.request.urlopen(url_page, timeout=5)\n",
    "            json_data = json.loads(json_page.read().decode())\n",
    "\n",
    "        if response_cache_path:\n",
    "            with open(f'{response_cache_path}/{location}_{start_d}_{end_d}', 'w') as f:\n",
    "                json.dump(json_data, f)\n",
    "        data = json_data['data']['weather']\n",
    "        # call function to extract json object\n",
    "        df_this_month = extract_monthly_data(data)\n",
    "        df_this_month['location'] = location\n",
    "        df_hist = pd.concat([df_hist, df_this_month])\n",
    "\n",
    "        time_elapsed = datetime.now() - start_time\n",
    "        print('Time elapsed (hh:mm:ss.ms) {}'.format(time_elapsed))\n",
    "    return (df_hist)\n",
    "\n",
    "\n",
    "##################################\n",
    "# main function to retrive the data by location list\n",
    "def retrieve_hist_data(api_key, location, start_date, end_date, frequency, location_label=False, export_csv=True,\n",
    "                       store_df=False, response_cache_path=None):\n",
    "    result_list = []\n",
    "    \n",
    "    print('\\n\\nRetrieving weather data for ' + location + '\\n\\n')\n",
    "    df_this_city = retrieve_this_location(api_key, location, start_date, end_date, frequency, response_cache_path)\n",
    "\n",
    "    if (location_label == True):\n",
    "            # add city name as prefix to the colnames\n",
    "        df_this_city = df_this_city.add_prefix(location + '_')\n",
    "        df_this_city.columns.values[0] = 'date_time'\n",
    "\n",
    "    if (export_csv == True):\n",
    "        df_this_city.to_csv('./' + location + '.csv', header=True, index=False)\n",
    "        print('\\n\\nexport ' + location + ' completed!\\n\\n')\n",
    "\n",
    "    if (store_df == True):\n",
    "            # save result as object in the work space\n",
    "        result_list.append(df_this_city)\n",
    "\n",
    "    return (result_list)\n",
    "lokasyonlar = ['usak']\n",
    "iller = ['erzurum','diyarbakır','adana','gaziantep','samsun','trabzon','manisa','ankara','konya','izmir','antalya','kayseri'\n",
    "        'bursa','tekirdag','denizli','istanbul']\n",
    "def hava_cek(locationn):\n",
    "    frequency=2\n",
    "    start_date = '01-JAN-2018'\n",
    "    end_date = '18-MAR-2021'\n",
    "    api_key = 'ea2f7452d098419f934121404210803'\n",
    "    hist_weather_data = retrieve_hist_data(api_key,\n",
    "                                       locationn,\n",
    "                                       start_date,\n",
    "                                       end_date,\n",
    "                                       frequency,\n",
    "                                       location_label = False,\n",
    "                                       export_csv = False,\n",
    "                                       store_df = True)\n",
    "    tablo = pd.DataFrame(data = hist_weather_data[0] )\n",
    "    path= \"A.xlsx\"\n",
    "    book = load_workbook(path)\n",
    "    writer = pd.ExcelWriter(path, engine = 'openpyxl')\n",
    "    writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "    writer.book = book\n",
    "    tablo.to_excel(writer,location)\n",
    "    writer.save()\n",
    "    #print(type(hist_weather_data))\n",
    "    writer.close()\n",
    "    return frequency\n",
    "for location in lokasyonlar:\n",
    "    hava_cek(location)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
